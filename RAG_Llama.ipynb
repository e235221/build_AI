{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c531f915",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yamawakidaiki/internship/AGAIN/RAG/lib/python3.12/site-packages/ibm_watsonx_ai/foundation_models/utils/utils.py:428: LifecycleWarning: Model 'ibm/granite-13b-instruct-v2' is in deprecated state from 2025-06-18 until 2025-10-15. IDs of alternative models: ibm/granite-3-3-8b-instruct. Further details: https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/fm-model-lifecycle.html?context=wx&audience=wdp\n",
      "  warn(model_state_warning, category=LifecycleWarning)\n"
     ]
    }
   ],
   "source": [
    "# 必要なライブラリをインポート\n",
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "# watsonx.aiのAPIキーとプロジェクトIDを環境変数に設定\n",
    "watsonx_api_key = \"0i-_-6pigerNnnRaU8_oiybRZz_UxMQuBHpE_copxSdw\"\n",
    "os.environ[\"WATSONX_APIKEY\"] = watsonx_api_key\n",
    "\n",
    "watsonx_project_id = \"b596c884-f867-4771-afcc-f9fd10dae1a4\"\n",
    "os.environ[\"WATSONX_PROJECT_ID\"] = watsonx_project_id\n",
    "\n",
    "# LlamaIndexとIBM WatsonX AIから必要なクラスをインポート\n",
    "from llama_index.llms.ibm import WatsonxLLM\n",
    "from ibm_watsonx_ai.metanames import GenTextParamsMetaNames\n",
    "\n",
    "# LLMの生成パラメータを設定\n",
    "rag_gen_parameters = {\n",
    "    GenTextParamsMetaNames.DECODING_METHOD: \"sample\",  # サンプリングを使用してテキストを生成\n",
    "    GenTextParamsMetaNames.MIN_NEW_TOKENS: 150,       # 生成する最小トークン数\n",
    "    GenTextParamsMetaNames.TEMPERATURE: 0.5,         # 生成テキストのランダム性を制御\n",
    "    GenTextParamsMetaNames.TOP_K: 5,                 # 上位K個のトークンからサンプリング\n",
    "    GenTextParamsMetaNames.TOP_P: 0.7                  # 上位Pの確率質量からサンプリング\n",
    "}\n",
    "\n",
    "# WatsonxLLMを初期化\n",
    "watsonx_llm = WatsonxLLM(\n",
    "    model_id=\"ibm/granite-13b-instruct-v2\",  # 使用するモデルのID\n",
    "    url=\"https://us-south.ml.cloud.ibm.com\", # watsonx.aiのエンドポイントURL\n",
    "    project_id=os.getenv(\"WATSONX_PROJECT_ID\"), # 環境変数からプロジェクトIDを取得\n",
    "    max_new_tokens=512, # 生成する最大トークン数\n",
    "    params=rag_gen_parameters, # 上で定義した生成パラメータを適用\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32f70476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDFファイルを読み込むためのPyMuPDFReaderをインポート\n",
    "from llama_index.readers.file import PyMuPDFReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddfed40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jupyter Notebookのような環境でasyncioのイベントループがネストされる問題を解決するためにnest_asyncioを適用します。\n",
    "# これにより、既存のイベントループ内で新しいイベントループを実行できるようになります。\n",
    "import asyncio, nest_asyncio\n",
    "\n",
    "# nest_asyncioを適用\n",
    "nest_asyncio.apply()\n",
    "# 現在のイベントループを取得\n",
    "loop = asyncio.get_event_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67687d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yamawakidaiki/internship/AGAIN/RAG/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.models.mluke.tokenization_mluke.MLukeTokenizer'> OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-10 15:26:42,335 - INFO - Load pretrained SentenceTransformer: pkshatech/GLuCoSE-base-ja\n"
     ]
    }
   ],
   "source": [
    "# checkpoint\n",
    "# トークナイザがSentencePieceを使って正常にロードできるか確認\n",
    "from transformers import AutoTokenizer\n",
    "# 日本語の事前学習済みモデルのトークナイザをロード\n",
    "tok = AutoTokenizer.from_pretrained(\"pkshatech/GLuCoSE-base-ja\")\n",
    "# トークナイザの型と\"OK\"メッセージを出力して、ロードが成功したことを確認\n",
    "print(type(tok), \"OK\")\n",
    "\n",
    "# HuggingFaceの埋め込みモデルとLlamaIndexのグローバル設定をインポート\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core import Settings\n",
    "\n",
    "# グローバル設定で、使用する埋め込みモデルをHuggingFaceのモデルに設定\n",
    "# これにより、以降の処理でこの埋め込みモデルがデフォルトで使用される\n",
    "Settings.embed_model = HuggingFaceEmbedding(\n",
    "    model_name=\"pkshatech/GLuCoSE-base-ja\"  # 日本語のテキストに適した埋め込みモデル\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "218f829a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-10 15:26:50,100 - INFO - Client successfully initialized\n",
      "2025-09-10 15:26:50,929 - INFO - HTTP Request: GET https://us-south.ml.cloud.ibm.com/ml/v1/foundation_model_specs?version=2025-08-27&project_id=b596c884-f867-4771-afcc-f9fd10dae1a4&filters=function_text_generation%2C%21lifecycle_withdrawn%3Aand&limit=200 \"HTTP/1.1 200 OK\"\n",
      "2025-09-10 15:26:50,929 - INFO - HTTP Request: GET https://us-south.ml.cloud.ibm.com/ml/v1/foundation_model_specs?version=2025-08-27&project_id=b596c884-f867-4771-afcc-f9fd10dae1a4&filters=function_text_generation%2C%21lifecycle_withdrawn%3Aand&limit=200 \"HTTP/1.1 200 OK\"\n",
      "2025-09-10 15:26:51,062 - INFO - Successfully finished Get available foundation models for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/foundation_model_specs?version=2025-08-27&project_id=b596c884-f867-4771-afcc-f9fd10dae1a4&filters=function_text_generation%2C%21lifecycle_withdrawn%3Aand&limit=200'\n",
      "2025-09-10 15:26:51,062 - INFO - Successfully finished Get available foundation models for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/foundation_model_specs?version=2025-08-27&project_id=b596c884-f867-4771-afcc-f9fd10dae1a4&filters=function_text_generation%2C%21lifecycle_withdrawn%3Aand&limit=200'\n",
      "2025-09-10 15:26:53,093 - INFO - Load pretrained SentenceTransformer: pkshatech/GLuCoSE-base-ja\n",
      "2025-09-10 15:26:53,093 - INFO - Load pretrained SentenceTransformer: pkshatech/GLuCoSE-base-ja\n",
      "2025-09-10 15:27:06,866 - DEBUG - Building index from IDs objects\n",
      "2025-09-10 15:27:06,866 - DEBUG - Building index from IDs objects\n"
     ]
    }
   ],
   "source": [
    "watsonx_llm = WatsonxLLM(\n",
    "\tmodel_id=\"meta-llama/llama-4-maverick-17b-128e-instruct-fp8\",\n",
    "\turl=\"https://us-south.ml.cloud.ibm.com\",\n",
    "\tproject_id=os.getenv(\"WATSONX_PROJECT_ID\"),\n",
    "\tmax_new_tokens=512,\n",
    "\tparams=rag_gen_parameters,\n",
    ")\n",
    "\n",
    "# トマトに関するpdfを読み込ませる。\n",
    "from llama_index.readers.file import PyMuPDFReader\n",
    "loader = PyMuPDFReader()\n",
    "# pdf_doc_ja = loader.load(file_path=\"./docs/housetomato.pdf\")\n",
    "pdf_doc_ja = loader.load(file_path=\"./docs/housetomato.pdf\")\n",
    "\n",
    "\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "# テキストを1024文字のチャンクに分割するスプリッターを定義\n",
    "splitter = SentenceSplitter(chunk_size=1024)\n",
    "\n",
    "# PDFドキュメントからベクトルストアインデックスを作成\n",
    "index = VectorStoreIndex.from_documents(\n",
    "\tpdf_doc_ja, transformations=[splitter],\n",
    "\tembed_model=Settings.embed_model # グローバル設定の埋め込みモデルを使用\n",
    ")\n",
    "\n",
    "# 日本語に対応した Embedding モデル に変更\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core import Settings\n",
    "Settings.embed_model = HuggingFaceEmbedding(\n",
    "\tmodel_name=\"pkshatech/GLuCoSE-base-ja\"\n",
    ")\n",
    "\n",
    "# ここから追加\n",
    "\n",
    "# 新しいドキュメントと設定でインデックスを再構築\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "# 日本語のテキストに適したチャンクサイズでスプリッターを再定義\n",
    "splitter = SentenceSplitter(chunk_size=512) # 日本語なのでチャンクサイズを調整\n",
    "# 日本語ドキュメントと新しい設定でベクトルストアインデックスを再構築\n",
    "index_ja = VectorStoreIndex.from_documents(\n",
    "    pdf_doc_ja, # 日本語のドキュメントを使用\n",
    "    transformations=[splitter],\n",
    "    embed_model=Settings.embed_model\n",
    ")\n",
    "\n",
    "# 新しいインデックスでリトリーバーを再構築\n",
    "from llama_index.retrievers.bm25 import BM25Retriever\n",
    "from llama_index.core.retrievers import QueryFusionRetriever\n",
    "\n",
    "# ベクトル検索用のリトリーバーを作成（類似度上位2件を取得）\n",
    "vector_retriever_ja = index_ja.as_retriever(similarity_top_k=2)\n",
    "# BM25（キーワードベース）検索用のリトリーバーを作成（類似度上位2件を取得）\n",
    "bm25_retriever_ja = BM25Retriever.from_defaults(\n",
    "    docstore=index_ja.docstore,\n",
    "    similarity_top_k=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbd6ce44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query Fusion Retrieverが使用するクエリ生成のプロンプトを定義\n",
    "# このプロンプトは、元のクエリから複数の異なる検索クエリを生成するようにLLMに指示する\n",
    "query_gen_prompt_str = (\n",
    "    \"あなたは、1つの入力クエリに基づいて複数の検索クエリを生成する有能なアシスタントです。\\n\"\n",
    "    \"{num_queries}個の検索クエリを、1行につき1つずつ生成してください。\\n\"\n",
    "    \"以下のクエリに関連する検索クエリを生成してください：\\n\"\n",
    "    \"\\n\"\n",
    "    \"クエリ: {query}\\n\"\n",
    "    \"検索クエリ:\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6ba4926",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-10 15:27:06,946 - DEBUG - Building index from IDs objects\n"
     ]
    }
   ],
   "source": [
    "# QueryFusionRetrieverとBM25Retrieverをインポート\n",
    "from llama_index.core.retrievers import QueryFusionRetriever\n",
    "from llama_index.retrievers.bm25 import BM25Retriever\n",
    "\n",
    "# グローバル設定でLLMをwatsonx_llmに設定\n",
    "Settings.llm = watsonx_llm\n",
    "\n",
    "# ベクトル検索用のリトリーバーを作成\n",
    "vector_retriever = index.as_retriever(similarity_top_k=2)\n",
    "\n",
    "# BM25検索用のリトリーバーを作成\n",
    "bm25_retriever = BM25Retriever.from_defaults(\n",
    "\tdocstore=index.docstore,\n",
    "\tsimilarity_top_k=2\n",
    ")\n",
    "\n",
    "# 複数のリトリーバーを組み合わせるQueryFusionRetrieverを作成\n",
    "retriever = QueryFusionRetriever(\n",
    "\t[vector_retriever, bm25_retriever], # ベクトル検索とBM25検索を組み合わせる\n",
    "\tsimilarity_top_k=4, # 最終的に返すドキュメントの数\n",
    "\tnum_queries=4,  # 生成する検索クエリの数\n",
    "\tmode=\"reciprocal_rerank\", # 検索結果をランク付けするモード\n",
    "\tuse_async=False, # 同期的に実行\n",
    "\tverbose=False, # 詳細なログ出力を無効化\n",
    "\tquery_gen_prompt=query_gen_prompt_str  # 上で定義したクエリ生成プロンプトを使用\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d36b225",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-10 15:27:07,790 - INFO - HTTP Request: GET https://us-south.ml.cloud.ibm.com/ml/v1/foundation_model_specs?version=2025-08-27&project_id=b596c884-f867-4771-afcc-f9fd10dae1a4&filters=function_text_generation%2C%21lifecycle_withdrawn%3Aand&limit=200 \"HTTP/1.1 200 OK\"\n",
      "2025-09-10 15:27:07,902 - INFO - Successfully finished Get next details for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/foundation_model_specs?version=2025-08-27&project_id=b596c884-f867-4771-afcc-f9fd10dae1a4&filters=function_text_generation%2C%21lifecycle_withdrawn%3Aand&limit=200'\n",
      "2025-09-10 15:27:07,902 - INFO - Successfully finished Get next details for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/foundation_model_specs?version=2025-08-27&project_id=b596c884-f867-4771-afcc-f9fd10dae1a4&filters=function_text_generation%2C%21lifecycle_withdrawn%3Aand&limit=200'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "日本語のドキュメントでインデックスとクエリエンジンを更新しました。\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 日本語設定でQueryFusionRetrieverを初期化\n",
    "retriever_ja = QueryFusionRetriever(\n",
    "    [vector_retriever_ja, bm25_retriever_ja], # 日本語用のリトリーバーを使用\n",
    "    similarity_top_k=4, # 最終的に返すドキュメントの数\n",
    "    num_queries=4, # 生成する検索クエリの数\n",
    "    mode=\"reciprocal_rerank\", # ランク付けモード\n",
    "    use_async=False, # 同期的に実行\n",
    "    verbose=False, # 詳細なログ出力を無効化\n",
    "    query_gen_prompt=query_gen_prompt_str # 日本語プロンプトを使用\n",
    ")\n",
    "\n",
    "\n",
    "# クエリエンジンを新しいリトリーバーで再構築\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "# 日本語用のリトリーバーを使ってクエリエンジンを作成\n",
    "query_engine = RetrieverQueryEngine(retriever_ja)\n",
    "print(\"日本語のドキュメントでインデックスとクエリエンジンを更新しました。\")\n",
    "\n",
    "# ベクトルを格納するためのインデックス を作成\n",
    "## 今回は システムプロンプトを日本語 に変更し、トマトに関する指示を与えるようにする。\n",
    "## 今回は「トマトの栽培方法」についての知識ベースとして使えるよう設定する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6311313f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RetrieverQueryEngineをインポート\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "# 上で作成したretriever（英語設定）を使用してクエリエンジンを作成\n",
    "query_engine = RetrieverQueryEngine(retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4aaa4df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-10 15:27:09,204 - INFO - HTTP Request: GET http://127.0.0.1:7860/gradio_api/startup-events \"HTTP/1.1 200 OK\"\n",
      "2025-09-10 15:27:09,216 - INFO - HTTP Request: HEAD http://127.0.0.1:7860/ \"HTTP/1.1 200 OK\"\n",
      "2025-09-10 15:27:09,216 - INFO - HTTP Request: HEAD http://127.0.0.1:7860/ \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-10 15:27:19,062 - INFO - HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-08-27 \"HTTP/1.1 200 OK\"\n",
      "2025-09-10 15:27:19,074 - INFO - Successfully finished generate for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-08-27'\n",
      "2025-09-10 15:27:19,074 - INFO - Successfully finished generate for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-08-27'\n",
      "2025-09-10 15:27:27,295 - INFO - HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-08-27 \"HTTP/1.1 200 OK\"\n",
      "2025-09-10 15:27:27,295 - INFO - HTTP Request: POST https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-08-27 \"HTTP/1.1 200 OK\"\n",
      "2025-09-10 15:27:27,306 - INFO - Successfully finished generate for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-08-27'\n",
      "2025-09-10 15:27:27,306 - INFO - Successfully finished generate for url: 'https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2025-08-27'\n"
     ]
    }
   ],
   "source": [
    "# Gradioライブラリをインポート\n",
    "import gradio as gr\n",
    "\n",
    "def chat_function(message, history):\n",
    "    \"\"\"\n",
    "    チャットメッセージを処理し、応答を生成します。\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # クエリエンジンでメッセージ（質問）を処理します。\n",
    "        response_obj = query_engine.query(message)\n",
    "        # 応答オブジェクトからテキスト部分を取得します。\n",
    "        response_text = response_obj.response\n",
    "    except Exception as e:\n",
    "        # エラーが発生した場合、エラーメッセージを返します。\n",
    "        response_text = f\"エラーが発生しました: {e}\"\n",
    "    return response_text\n",
    "\n",
    "# GradioのChatInterfaceを作成\n",
    "demo = gr.ChatInterface(\n",
    "    fn=chat_function, # チャットの応答を生成する関数\n",
    "    title=\"Llama\", # インターフェースのタイトル\n",
    "    theme=\"soft\", # UIのテーマ\n",
    "    examples=[ # ユーザーに示す質問の例\n",
    "        \"トマトを家庭で育てるにはどうすればよいですか？\",\n",
    "        \"トマトの栽培に最適な気候や土壌条件は何ですか？\"\n",
    "    ],\n",
    "    type='messages' # メッセージ形式のインターフェース\n",
    ")\n",
    "\n",
    "# Gradioアプリケーションを起動します。\n",
    "demo.launch(inline=True, share=False) # インラインで表示し、共有リンクは作成しない"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
